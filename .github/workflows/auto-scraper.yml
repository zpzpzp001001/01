name: Auto Content Scraper

on:
  # n8n ì›¹í›…ìœ¼ë¡œ íŠ¸ë¦¬ê±°
  repository_dispatch:
    types: [scrape-content]
  
  # ìˆ˜ë™ ì‹¤í–‰ë„ ê°€ëŠ¥
  workflow_dispatch:
    inputs:
      sitemap_url:
        description: 'Sitemap URL to scrape'
        required: false
        default: 'https://www.reportera.co.kr/sitemap.xml'

permissions:
  contents: write

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.PAT_TOKEN || secrets.GITHUB_TOKEN }}
          
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          
      - name: Install Python dependencies
        run: |
          pip install -r requirements.txt
          
      - name: Create content directory
        run: |
          mkdir -p content
          
      - name: Test email configuration
        env:
          SENDER_EMAIL: ${{ secrets.SENDER_EMAIL }}
          SENDER_PASSWORD: ${{ secrets.SENDER_PASSWORD }}
          RECIPIENT_EMAIL: ${{ secrets.RECIPIENT_EMAIL }}
        run: |
          echo "ğŸ“§ Testing email configuration..."
          if [ -z "$SENDER_EMAIL" ] || [ -z "$SENDER_PASSWORD" ] || [ -z "$RECIPIENT_EMAIL" ]; then
            echo "âš ï¸ Email configuration incomplete - email reports will be skipped"
          else
            echo "âœ… Email configuration detected"
          fi
          
      - name: Run AI scraper with email reporting
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          SENDER_EMAIL: ${{ secrets.SENDER_EMAIL }}
          SENDER_PASSWORD: ${{ secrets.SENDER_PASSWORD }}
          RECIPIENT_EMAIL: ${{ secrets.RECIPIENT_EMAIL }}
          OPENAI_MODEL: 'gpt-4o-mini'
          SITEMAP_URL: ${{ github.event.inputs.sitemap_url || 'https://www.reportera.co.kr/news-sitemap.xml' }}
        run: |
          echo "ğŸš€ Starting AI-powered scraper with email reporting"
          echo "ğŸ“¥ Sitemap: $SITEMAP_URL"
          echo "ğŸ“§ Email reports: $([ -n "$SENDER_EMAIL" ] && echo 'Enabled' || echo 'Disabled')"
          python ai_scraper.py
          
      - name: Send error report email (if scraper failed)
        if: failure()
        env:
          SENDER_EMAIL: ${{ secrets.SENDER_EMAIL }}
          SENDER_PASSWORD: ${{ secrets.SENDER_PASSWORD }}
          RECIPIENT_EMAIL: ${{ secrets.RECIPIENT_EMAIL }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          OPENAI_MODEL: 'gpt-4o-mini'
        run: |
          echo "âŒ Scraper failed - sending error report email"
          python send_email.py error "GitHub Actions ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨"
          
      - name: Commit and push changes
        if: success()
        env:
          PAT_TOKEN: ${{ secrets.PAT_TOKEN }}
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # __pycache__ í´ë” ì œê±° (Gitì— ì¶”ê°€ë˜ì§€ ì•Šë„ë¡)
          find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
          
          # content/ í´ë”ì™€ ë°ì´í„°ë² ì´ìŠ¤ë§Œ ì¶”ê°€
          git add content/ 2>/dev/null || true
          git add processed_articles.db 2>/dev/null || true
          
          # ë³€ê²½ì‚¬í•­ì´ ìˆëŠ”ì§€ í™•ì¸ (staged filesë§Œ)
          if [ -n "$(git diff --cached --name-only)" ]; then
            echo "ğŸ“ Changes detected - committing..."
            git commit -m "ğŸ¤– Auto-generated content $(date '+%Y-%m-%d %H:%M:%S')"
            
            # PAT í† í°ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ í† í° ì‚¬ìš©
            if [ -n "$PAT_TOKEN" ]; then
              git remote set-url origin https://x-access-token:${PAT_TOKEN}@github.com/${{ github.repository }}.git
            fi
            
            git push
            echo "âœ… Changes pushed successfully"
          else
            echo "â„¹ï¸ No changes to commit"
          fi
          
      - name: Notify completion
        if: steps.check_changes.outputs.has_changes == 'true'
        run: |
          echo "âœ… Content scraping completed and pushed to repository"
          echo "ğŸš€ Cloudflare Pages will automatically deploy the changes"
          
      - name: No changes notification
        if: steps.check_changes.outputs.has_changes == 'false'
        run: |
          echo "â„¹ï¸ No new content found to scrape" 